{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fafb87b1-59d6-4cc1-8973-d6f5f3243346",
   "metadata": {},
   "source": [
    "# Data Cleaning Phase II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0571a38c",
   "metadata": {},
   "source": [
    "In this notebook, you will do the following:\n",
    "* Section 1: Data Cleaning\n",
    "* Section 2: Data Quality and Testing\n",
    "* Section 3: Work Flow Model\n",
    "* Section 4: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf61704e-8aab-4e1e-afb5-d55e088e1873",
   "metadata": {},
   "source": [
    "## Section 1: Data Cleaning Steps\n",
    "Data cleaning for this project was done with two tools, OpenRefine and Python. We used OpenRefine to trim whitespace and do data type conversions. We use Python for key constraints, empty/null values, outliers, and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06cfba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0ff57-bb6a-4b4c-b14f-50a6081e68ac",
   "metadata": {},
   "source": [
    "### OpenRefine: Dish dataset cleaning\n",
    "\n",
    "**Step 1.1**\n",
    "\n",
    "**Description:** We trim the whitespace from the dish name and we convert the prices to number values.\n",
    "\n",
    "**Rationale:** Trimming the dish name whitespace will allow us to more accurately find duplicate dishes and better track prices over time. Converting prices to numbers will help us run calculations that can't be run on a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197dbfac-68be-45dd-917b-a45748d80cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"op\": \"core/text-transform\",\\n    \"engineConfig\": {\\n      \"facets\": [],\\n      \"mode\": \"row-based\"\\n    },\\n    \"columnName\": \"name\",\\n    \"expression\": \"value.trim()\",\\n    \"onError\": \"keep-original\",\\n    \"repeat\": false,\\n    \"repeatCount\": 10,\\n    \"description\": \"Text transform on cells in column name using expression value.trim()\"\\n  },\\n  {\\n    \"op\": \"core/text-transform\",\\n    \"engineConfig\": {\\n      \"facets\": [],\\n      \"mode\": \"row-based\"\\n    },\\n    \"columnName\": \"lowest_price\",\\n    \"expression\": \"value.toNumber()\",\\n    \"onError\": \"keep-original\",\\n    \"repeat\": false,\\n    \"repeatCount\": 10,\\n    \"description\": \"Text transform on cells in column lowest_price using expression value.toNumber()\"\\n  },\\n  {\\n    \"op\": \"core/text-transform\",\\n    \"engineConfig\": {\\n      \"facets\": [],\\n      \"mode\": \"row-based\"\\n    },\\n    \"columnName\": \"highest_price\",\\n    \"expression\": \"value.toNumber()\",\\n    \"onError\": \"keep-original\",\\n    \"repeat\": false,\\n    \"repeatCount\": 10,\\n    \"description\": \"Text transform on cells in column highest_price using expression value.toNumber()\"\\n  }\\n]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"[\n",
    "  {\n",
    "    \"op\": \"core/text-transform\",\n",
    "    \"engineConfig\": {\n",
    "      \"facets\": [],\n",
    "      \"mode\": \"row-based\"\n",
    "    },\n",
    "    \"columnName\": \"name\",\n",
    "    \"expression\": \"value.trim()\",\n",
    "    \"onError\": \"keep-original\",\n",
    "    \"repeat\": false,\n",
    "    \"repeatCount\": 10,\n",
    "    \"description\": \"Text transform on cells in column name using expression value.trim()\"\n",
    "  },\n",
    "  {\n",
    "    \"op\": \"core/text-transform\",\n",
    "    \"engineConfig\": {\n",
    "      \"facets\": [],\n",
    "      \"mode\": \"row-based\"\n",
    "    },\n",
    "    \"columnName\": \"lowest_price\",\n",
    "    \"expression\": \"value.toNumber()\",\n",
    "    \"onError\": \"keep-original\",\n",
    "    \"repeat\": false,\n",
    "    \"repeatCount\": 10,\n",
    "    \"description\": \"Text transform on cells in column lowest_price using expression value.toNumber()\"\n",
    "  },\n",
    "  {\n",
    "    \"op\": \"core/text-transform\",\n",
    "    \"engineConfig\": {\n",
    "      \"facets\": [],\n",
    "      \"mode\": \"row-based\"\n",
    "    },\n",
    "    \"columnName\": \"highest_price\",\n",
    "    \"expression\": \"value.toNumber()\",\n",
    "    \"onError\": \"keep-original\",\n",
    "    \"repeat\": false,\n",
    "    \"repeatCount\": 10,\n",
    "    \"description\": \"Text transform on cells in column highest_price using expression value.toNumber()\"\n",
    "  }\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f348c6-6317-4c1e-bf7c-c5bfa0e9c416",
   "metadata": {},
   "source": [
    "### OpenRefine: Menu Item Cleaning\n",
    "\n",
    "**Step 1.2**\n",
    "\n",
    "**Description:** We convert the prices to number values and we trim off the timestamp and convert the datestring to a date type.\n",
    "\n",
    "**Rationale:** Converting prices and dates will help us run calculations that can't be run on a string. We trim times from menu item dates so that we can assess dish price with less granularity. This way we can group menu items by their date instead of having menu items all at different times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9467f379-3de3-4761-b5b1-1c033d68ba22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"op\": \"core/text-transform\",\\n    \"engineConfig\": {\\n      \"facets\": [],\\n      \"mode\": \"row-based\"\\n    },\\n    \"columnName\": \"price\",\\n    \"expression\": \"value.toNumber()\",\\n    \"onError\": \"keep-original\",\\n    \"repeat\": false,\\n    \"repeatCount\": 10,\\n    \"description\": \"Text transform on cells in column price using expression value.toNumber()\"\\n  },\\n  {\\n    \"op\": \"core/text-transform\",\\n    \"engineConfig\": {\\n      \"facets\": [],\\n      \"mode\": \"row-based\"\\n    },\\n    \"columnName\": \"high_price\",\\n    \"expression\": \"value.toNumber()\",\\n    \"onError\": \"keep-original\",\\n    \"repeat\": false,\\n    \"repeatCount\": 10,\\n    \"description\": \"Text transform on cells in column high_price using expression value.toNumber()\"\\n  },\\n  {\\n    \"op\": \"core/text-transform\",\\n    \"engineConfig\": {\\n      \"facets\": [],\\n      \"mode\": \"row-based\"\\n    },\\n    \"columnName\": \"created_at\",\\n    \"expression\": \"grel:value[0,10]\",\\n    \"onError\": \"keep-original\",\\n    \"repeat\": false,\\n    \"repeatCount\": 10,\\n    \"description\": \"Text transform on cells in column created_at using expression grel:value[0,10]\"\\n  },\\n  {\\n    \"op\": \"core/text-transform\",\\n    \"engineConfig\": {\\n      \"facets\": [],\\n      \"mode\": \"row-based\"\\n    },\\n    \"columnName\": \"updated_at\",\\n    \"expression\": \"grel:value[0,10]\",\\n    \"onError\": \"keep-original\",\\n    \"repeat\": false,\\n    \"repeatCount\": 10,\\n    \"description\": \"Text transform on cells in column updated_at using expression grel:value[0,10]\"\\n  },\\n  {\\n    \"op\": \"core/text-transform\",\\n    \"engineConfig\": {\\n      \"facets\": [],\\n      \"mode\": \"row-based\"\\n    },\\n    \"columnName\": \"created_at\",\\n    \"expression\": \"value.toDate()\",\\n    \"onError\": \"keep-original\",\\n    \"repeat\": false,\\n    \"repeatCount\": 10,\\n    \"description\": \"Text transform on cells in column created_at using expression value.toDate()\"\\n  },\\n  {\\n    \"op\": \"core/text-transform\",\\n    \"engineConfig\": {\\n      \"facets\": [],\\n      \"mode\": \"row-based\"\\n    },\\n    \"columnName\": \"updated_at\",\\n    \"expression\": \"value.toDate()\",\\n    \"onError\": \"keep-original\",\\n    \"repeat\": false,\\n    \"repeatCount\": 10,\\n    \"description\": \"Text transform on cells in column updated_at using expression value.toDate()\"\\n  }\\n]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"[\n",
    "  {\n",
    "    \"op\": \"core/text-transform\",\n",
    "    \"engineConfig\": {\n",
    "      \"facets\": [],\n",
    "      \"mode\": \"row-based\"\n",
    "    },\n",
    "    \"columnName\": \"price\",\n",
    "    \"expression\": \"value.toNumber()\",\n",
    "    \"onError\": \"keep-original\",\n",
    "    \"repeat\": false,\n",
    "    \"repeatCount\": 10,\n",
    "    \"description\": \"Text transform on cells in column price using expression value.toNumber()\"\n",
    "  },\n",
    "  {\n",
    "    \"op\": \"core/text-transform\",\n",
    "    \"engineConfig\": {\n",
    "      \"facets\": [],\n",
    "      \"mode\": \"row-based\"\n",
    "    },\n",
    "    \"columnName\": \"high_price\",\n",
    "    \"expression\": \"value.toNumber()\",\n",
    "    \"onError\": \"keep-original\",\n",
    "    \"repeat\": false,\n",
    "    \"repeatCount\": 10,\n",
    "    \"description\": \"Text transform on cells in column high_price using expression value.toNumber()\"\n",
    "  },\n",
    "  {\n",
    "    \"op\": \"core/text-transform\",\n",
    "    \"engineConfig\": {\n",
    "      \"facets\": [],\n",
    "      \"mode\": \"row-based\"\n",
    "    },\n",
    "    \"columnName\": \"created_at\",\n",
    "    \"expression\": \"grel:value[0,10]\",\n",
    "    \"onError\": \"keep-original\",\n",
    "    \"repeat\": false,\n",
    "    \"repeatCount\": 10,\n",
    "    \"description\": \"Text transform on cells in column created_at using expression grel:value[0,10]\"\n",
    "  },\n",
    "  {\n",
    "    \"op\": \"core/text-transform\",\n",
    "    \"engineConfig\": {\n",
    "      \"facets\": [],\n",
    "      \"mode\": \"row-based\"\n",
    "    },\n",
    "    \"columnName\": \"updated_at\",\n",
    "    \"expression\": \"grel:value[0,10]\",\n",
    "    \"onError\": \"keep-original\",\n",
    "    \"repeat\": false,\n",
    "    \"repeatCount\": 10,\n",
    "    \"description\": \"Text transform on cells in column updated_at using expression grel:value[0,10]\"\n",
    "  },\n",
    "  {\n",
    "    \"op\": \"core/text-transform\",\n",
    "    \"engineConfig\": {\n",
    "      \"facets\": [],\n",
    "      \"mode\": \"row-based\"\n",
    "    },\n",
    "    \"columnName\": \"created_at\",\n",
    "    \"expression\": \"value.toDate()\",\n",
    "    \"onError\": \"keep-original\",\n",
    "    \"repeat\": false,\n",
    "    \"repeatCount\": 10,\n",
    "    \"description\": \"Text transform on cells in column created_at using expression value.toDate()\"\n",
    "  },\n",
    "  {\n",
    "    \"op\": \"core/text-transform\",\n",
    "    \"engineConfig\": {\n",
    "      \"facets\": [],\n",
    "      \"mode\": \"row-based\"\n",
    "    },\n",
    "    \"columnName\": \"updated_at\",\n",
    "    \"expression\": \"value.toDate()\",\n",
    "    \"onError\": \"keep-original\",\n",
    "    \"repeat\": false,\n",
    "    \"repeatCount\": 10,\n",
    "    \"description\": \"Text transform on cells in column updated_at using expression value.toDate()\"\n",
    "  }\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ee03d-d5b0-4d75-85d3-fd557e81e110",
   "metadata": {},
   "source": [
    "### Python: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd4d1c-36bc-450f-9001-da128baaefa5",
   "metadata": {},
   "source": [
    "**Step 1.3**\n",
    "\n",
    "**Description:** First we import the libraries we will be using and the datasets that we will be cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f01ee38-007b-4b2d-bcad-f532682ec69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pytest\n",
    "\n",
    "dish_df = pd.read_csv(\"open_refine_cleaned/Dish.csv\")\n",
    "menu_item_df = pd.read_csv(\"open_refine_cleaned/Menu-Item.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7016b0-7ea3-4444-ba27-9d08db064b87",
   "metadata": {},
   "source": [
    "**Step 1.4**\n",
    "\n",
    "**Description:** We drop the rows that have an empty/null value for \"price\" and \"created_at\" columns.\n",
    "\n",
    "**Rationale:** Our use case deals with comparing menu item prices throughout time, we can’t analyze menu items if the dates or prices of that item are null. Since we have enough data even when removing the empty values we decided to remove all of the empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8554d2a9-794e-4f26-bd64-f57204599fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_item_df.dropna(subset=['price'], inplace=True)\n",
    "menu_item_df.dropna(subset=['created_at'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4125f4-7d5b-426e-97fb-012ea9fa5df2",
   "metadata": {},
   "source": [
    "**Step 1.5**\n",
    "\n",
    "**Description:** Convert the dish names to title case.\n",
    "\n",
    "**Rationale:** Similar to trimming the dish names, converting the dish names to title case will allow us to more accurately detect duplipcates and merge them for better price tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f93fb458-b969-4179-8f20-d26dfe6bf36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dish_df[\"name\"] = dish_df[\"name\"].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8283bf6-316d-436e-a540-0ae28dc81c60",
   "metadata": {},
   "source": [
    "**Step 1.6**\n",
    "\n",
    "**Description:** Find all dishes with the same name and grouping them together.\n",
    "Setting all the duplicate dish menu items to the first dish id.\n",
    "Removing all but the first dishes from the dish data set.\n",
    "\n",
    "**Rationale:** Many dish names are similar/duplicates of each other, so they may be referring to the same food item, but under different dish_ids. We find these duplicates and merge them allowing us to have more data points per dish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5bea8e3-e1d4-42ee-b57d-de0f2802c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = dish_df[\"name\"]\n",
    "duped_name = dish_df[ids.isin(ids[ids.duplicated()])].sort_values(\"name\")\n",
    "duped_ids = duped_name.groupby(['name'])['id'].apply(lambda x: ','.join([str(y) for y in x])).reset_index()\n",
    "ids_to_drop = []\n",
    "\n",
    "for row in duped_ids.iterrows():\n",
    "    dish_ids = row[1][\"id\"].split(\",\")\n",
    "    first = int(dish_ids[0])\n",
    "    for id in dish_ids[1:]:\n",
    "        ids_to_drop.append(int(id))\n",
    "        menu_item_df.loc[menu_item_df[\"dish_id\"] == int(id), \"dish_id\"] = first\n",
    "        \n",
    "dish_df = dish_df[~dish_df['id'].isin(ids_to_drop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbbca04-0d36-4c52-94f0-7ff09c244259",
   "metadata": {},
   "source": [
    "**Step 1.7**\n",
    "\n",
    "**Description:** Removing menu items that have prices outside the 10th-90th percentile.\n",
    "\n",
    "**Rationale:** Removing outliers will allow us to more accurately analyze the changes in price over time. If a handful of dishes skyrocket in price, but they were a small part of all dishes, then that could skew the analysis. Therefore we removed all data points where the price was outside of the 10th-90th percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d16f0735-4c13-4fae-ac5d-15f8e9225dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_low = menu_item_df[\"price\"].quantile(0.10)\n",
    "q_hi  = menu_item_df[\"price\"].quantile(0.90)\n",
    "iqr = q_hi - q_low\n",
    "mul = 2.0\n",
    "\n",
    "menu_item_df = menu_item_df[(menu_item_df[\"price\"] < q_hi + mul * iqr) & (menu_item_df[\"price\"] > q_low - mul * iqr)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62645e-5c79-47f5-996a-cd0f1d219386",
   "metadata": {},
   "source": [
    "**Step 1.8**\n",
    "\n",
    "**Description:** Use min-max normalization for the menu item prices.\n",
    "\n",
    "**Rationale:** Normalizing the price data isn’t absolutely necessary for this investigation, but will help keep our data uniform and easy to read and understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529a29ab-bdc2-4a33-8664-b11528babfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_item_df[\"price\"] = (menu_item_df[\"price\"] - menu_item_df[\"price\"].min()) / (menu_item_df[\"price\"].max() - menu_item_df[\"price\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b481e165-2fa5-4f85-8d2d-cb93a97178cb",
   "metadata": {},
   "source": [
    "**Step 1.9**\n",
    "\n",
    "**Description:** Removing menu items that don’t have a particular dish associated with it and removing dishes that have no menu items associated with it.\n",
    "\n",
    "**Rationale:** If a menu item doesn't have an associated dish in the dish dataset, then we don’t want to consider it since that may be an invalid entry or it may not be possible to track its price over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f4a89f-a972-4b2b-9dd8-3174fbc93850",
   "metadata": {},
   "outputs": [],
   "source": [
    "dish_df = dish_df[dish_df['id'].isin(menu_item_df[\"dish_id\"])]\n",
    "menu_item_df = menu_item_df[menu_item_df['dish_id'].isin(dish_df[\"id\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bfde53",
   "metadata": {},
   "source": [
    "**Step 1.10**\n",
    "\n",
    "**Description:** Standardizing the created_at into ISO format.\n",
    "\n",
    "**Rationale:** In order to analyze the dish prices over time, we need a standard date format for the created_at field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b31c32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_item_df['created_at'] = pd.to_datetime(menu_item_df['created_at'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e243763-9946-4ce5-848f-9d489eddb183",
   "metadata": {},
   "source": [
    "**Step 1.11**\n",
    "\n",
    "**Description:** Write the cleaned data to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1299c30-3b5b-4af5-a6bc-ae7e5239bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write cleaned data to files\n",
    "dish_df.to_csv(\"python_cleaned/Dish.csv\", index=False)\n",
    "menu_item_df.to_csv(\"python_cleaned/Menu-Item.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2250e",
   "metadata": {},
   "source": [
    "## Section 2: Document Data Quality Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd3e774",
   "metadata": {},
   "source": [
    "**Description:** Run a series of tests to prove that the data quality has been improved.\n",
    "\n",
    "**Rationale:** We compare and contrast the uncleaned versus the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c613c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dish_df_uncleaned = pd.read_csv(\"open_refine_cleaned/Dish.csv\")\n",
    "menu_item_df_uncleaned = pd.read_csv(\"open_refine_cleaned/Menu-Item.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f809cb",
   "metadata": {},
   "source": [
    "**Step 2.1a**\n",
    "\n",
    "**Description:** Provide a high level summary of the cleaned versus uncleaned data frames for the dish_df.\n",
    "\n",
    "**Test Type:** Data Completeness\n",
    "\n",
    "**Rationale:** We know that many dish names are similar/duplicates of each other, so they may be referring to the same food item, but under different dish_ids. We removed these duplicates, which would explain why the cleaned dish_df has 232,874 ids versus the uncleaned dish_df which has 423,397."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f6d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dish_df_uncleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dish_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db600b56",
   "metadata": {},
   "source": [
    "**Step 2.1b**\n",
    "\n",
    "**Description:** Provide a high level summary of the cleaned versus uncleaned data frames for the menu_item_df.\n",
    "\n",
    "**Test Type:** Data Completeness\n",
    "\n",
    "**Rationale:** We dropped menu items that don't have an associated dish in the dish dataset, which would explain why the cleaned menu_item_df has 846,136 ids versus the uncleaned menu_item_df which has 1,332,726 ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_item_df_uncleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fb5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_item_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27b7696",
   "metadata": {},
   "source": [
    "**Step 2.2**\n",
    "\n",
    "**Test Type:** Data Completeness\n",
    "\n",
    "**Description:** Test to see if there are still missing dish prices.\n",
    "\n",
    "**Rationale:** In step 1.4 we removed dishes with a null price, the following test will assure that there are no dishes with missing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7510c0b9-fe09-4d83-a457-2b75f04e6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_missing_dish_prices(menu_item_df):\n",
    "    missing_dish_price = menu_item_df[\"price\"].isnull().sum()\n",
    "    assert (\n",
    "        missing_dish_price == 0\n",
    "    ), f\"There are {missing_dish_price} missing dish prices\"\n",
    "    print('Test passed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3b36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_missing_dish_prices(menu_item_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d6729",
   "metadata": {},
   "source": [
    "**Step 2.3**\n",
    "\n",
    "**Test Type:** Data Completeness\n",
    "\n",
    "**Description:** Test to see if there are still missing created dates.\n",
    "\n",
    "**Rationale:** Each item on the menu needs a created at date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d33e6d-6c6a-434d-9180-460706b2b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_missing_created_dates(menu_item_df):\n",
    "    missing_created_at = menu_item_df[\"created_at\"].isnull().sum()\n",
    "    assert (\n",
    "        missing_created_at == 0\n",
    "    ), f\"There are {missing_created_at} missing created at date\"\n",
    "    print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_missing_created_dates(menu_item_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6214fb58",
   "metadata": {},
   "source": [
    "**Step 2.4**\n",
    "\n",
    "**Test Type:** Integrity Constraint Violations\n",
    "\n",
    "**Description:** Test to see if there is a valid iso format for dates.\n",
    "\n",
    "**Rationale:** In order to compare dish prices over time, the dates must be in the proper format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2e88c-78fd-48aa-a000-8070c4a5b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_created_at_datetime(menu_item_df):\n",
    "    try:\n",
    "        pd.to_datetime(menu_item_df['created_at'])\n",
    "        is_datetime = True\n",
    "    except ValueError:\n",
    "        is_datetime = False\n",
    "    assert (\n",
    "        is_datetime\n",
    "    ), f\"'created_at' column is of type {menu_item_df['created_at'].dtype}, and couldn't be converted to datetime\"\n",
    "    print('Test passed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0288b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_created_at_datetime(menu_item_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e06e55",
   "metadata": {},
   "source": [
    "**Step 2.5**\n",
    "\n",
    "**Test Type:** Integrity Constraint Violations\n",
    "\n",
    "**Description:** Test to see if are no duplicate dish names.\n",
    "\n",
    "**Rationale:** In order to compare dishes properly, we need to remove duplicates.  We did this in step 1.6 in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbd0eda-626a-4fec-82e0-a640a9a6e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function to check for duplicate names\n",
    "def test_no_duplicate_names(dish_df):\n",
    "    duplicate_names = dish_df.groupby([\"name\"])[\"name\"].count()\n",
    "    num_duplicate_names = duplicate_names[duplicate_names > 1].count()\n",
    "\n",
    "    assert (\n",
    "        num_duplicate_names == 0\n",
    "    ), f\"There are {num_duplicate_names} duplicate dish names\"\n",
    "    print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4b9a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_no_duplicate_names(dish_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df417d25",
   "metadata": {},
   "source": [
    "**Step 2.6**\n",
    "\n",
    "**Test Type:** Integrity Constraint Violations\n",
    "\n",
    "**Description:** Test to ensure there are no leading or trailing whitespaces.\n",
    "\n",
    "**Rationale:** In order to compare dishes properly, we need to remove duplicates.  We did this in step 1.1 with OpenRefine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e9e878-34a1-4260-b858-64026bea67a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_no_leading_trailing_whitespace(dish_df):\n",
    "    dirty_dish_names = (\n",
    "        dish_df[\"name\"].apply(lambda x: isinstance(x, str) and (x.strip() != x)).sum()\n",
    "    )\n",
    "\n",
    "    assert (\n",
    "        dirty_dish_names == 0\n",
    "    ), f\"There are {dirty_dish_names} dish names with leading and trailing whitespace\"\n",
    "    print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76727681",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no_leading_trailing_whitespace(dish_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbe6ce3",
   "metadata": {},
   "source": [
    "**Step 2.7**\n",
    "\n",
    "**Test Type:** Integrity Constraint Violations\n",
    "\n",
    "**Description:** Test to ensure dish names are formatted consistently with title case.\n",
    "\n",
    "**Rationale:** In order to compare dishes properly, we need each name to be in title case.  We did this in step 1.5 in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e98e4f-0400-46a4-8b9a-0959e9fc2b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_name_consistent_format(dish_df):\n",
    "    inconsistent_format_count = 0\n",
    "\n",
    "    for name in dish_df[\"name\"]:\n",
    "        if not isinstance(name, str):\n",
    "            # check if the data is of type string\n",
    "            inconsistent_format_count += 1\n",
    "        elif name != name.title():\n",
    "            # check if the name is in title case\n",
    "            inconsistent_format_count += 1\n",
    "\n",
    "    assert (\n",
    "        inconsistent_format_count == 0\n",
    "    ), f\"There are {inconsistent_format_count} names with inconsistent format\"\n",
    "    print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd5203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name_consistent_format(dish_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61932792",
   "metadata": {},
   "source": [
    "**Step 2.8**\n",
    "\n",
    "**Test Type:** Consistency\n",
    "\n",
    "**Description:** Test to ensure that outliers have been removed.\n",
    "\n",
    "**Rationale:** In order to avoid data skewing we need to remove outliers.  We removed outliers in section 1.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40bcc7e-3c27-4089-99d6-1c5eba8fcbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_removed(olddataframe, dataframe, column_name, multiplier=1.5):\n",
    "    Q1 = olddataframe[column_name].quantile(0.10)\n",
    "    Q3 = olddataframe[column_name].quantile(0.90)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Count the number of outliers\n",
    "    outliers = dataframe[\n",
    "        (dataframe[column_name] < Q1 - multiplier * IQR)\n",
    "        | (dataframe[column_name] > Q3 + multiplier * IQR)\n",
    "    ]\n",
    "    outliers_count = outliers.shape[0]\n",
    "\n",
    "    assert outliers_count == 0, f\"There are {outliers_count} outliers in {column_name}\"\n",
    "\n",
    "def test_menu_item_price_outliers(old_menu_item_df, menu_item_df):\n",
    "    outliers_removed(old_menu_item_df, menu_item_df, \"price\", multiplier=2.0)\n",
    "    print('test passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad7517",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_menu_item_price_outliers(menu_item_df_uncleaned, menu_item_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b055e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_item_df_uncleaned.price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1961cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_item_df.price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b7dda",
   "metadata": {},
   "source": [
    "**Step 2.9**\n",
    "\n",
    "**Test Type:** Consistency\n",
    "\n",
    "**Description:** Test to ensure that the data has min-max normalization.\n",
    "\n",
    "**Rationale:** The price needs to be on the same scale so that each item is equally weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_price_normalization(menu_item_df):\n",
    "    min_price = menu_item_df['price'].min()\n",
    "    max_price = menu_item_df['price'].max()\n",
    "    \n",
    "    assert min_price == 0, f\"Minimum price is {min_price}, expected 0 after normalization\"\n",
    "    assert max_price == 1, f\"Maximum price is {max_price}, expected 1 after normalization\"\n",
    "    \n",
    "    # To additionally check if there are any values outside the [0,1] range\n",
    "    assert not ((menu_item_df['price'] < 0).any() or (menu_item_df['price'] > 1).any()), \"There are 'price' values outside the [0,1] range after normalization\"\n",
    "    \n",
    "    print('Test passed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e8b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_price_normalization(menu_item_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288253ca",
   "metadata": {},
   "source": [
    "## Section 3: Work Flow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9583933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3337237d",
   "metadata": {},
   "source": [
    "## Section 4: Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f622ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
